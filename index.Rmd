---
title: "Vaccination Data Analysis"
author: "G.Mohan Teja 19BEC1133,Aman Verma 19BEC1284,Ayush Singh 19BEC1032,Janhavi Kulkarni 19BLC1187"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Reading data

```{r}
library(readr)
vaccinations <- read_csv(url("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv"),show_col_types = FALSE)
newCases <- read_csv(url("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/jhu/new_cases_per_million.csv"),show_col_types = FALSE)
deaths <- read_csv(url("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/jhu/total_deaths_per_million.csv"),show_col_types = FALSE)
```

## Subsetting the Data

### Note :

new cases and deaths are taken per million and vaccinations are taken per 100

```{r}
ind <-vaccinations[vaccinations[1]=="India",]
vaxIndia <- data.frame(ind$date,ind$people_fully_vaccinated_per_hundred)
summary(vaxIndia)
newCasesIndia <- data.frame(newCases$date,newCases$India)
summary(newCasesIndia)
deathsIndia <- data.frame(deaths$date,deaths$India)
summary(deathsIndia)
```

## Cleaning Data

### Na values

As we can see there are Na values in the data and timelines don't algin correctly we can fill na with previous know values since this is a time series data so we fill na with previous known values and remaining na with 0

```{r}
fill.NAs <- function(x) {is_na<-is.na(x); x[Reduce(function(i,j) if (is_na[j]) i else j, seq_len(length(x)), accumulate=T)]}
vaxIndia$ind.people_fully_vaccinated_per_hundred <- fill.NAs(vaxIndia$ind.people_fully_vaccinated_per_hundred)
vaxIndia[is.na(vaxIndia)] = 0
summary(vaxIndia)
newCasesIndia$newCases.India <- fill.NAs(newCasesIndia$newCases.India)
newCasesIndia[is.na(newCasesIndia)] = 0 
summary(newCasesIndia)
deathsIndia$deaths.India <- fill.NAs(deathsIndia$deaths.India)
deathsIndia[is.na(deathsIndia)] = 0
summary(deathsIndia)
firstcasedate<-newCasesIndia$newCases.date[1]
latestcasedate<-newCasesIndia$newCases.date[length(newCasesIndia$newCases.date)]
firstvaxdate<-vaxIndia$ind.date[1]
latestvaxdate<-vaxIndia$ind.date[length(vaxIndia$ind.date)]
firstdeathdate<-deathsIndia$deaths.date[1]
latestdeathdate<-deathsIndia$deaths.date[length(deathsIndia$deaths.date)]
```

### Dates

```{r}
vaxIndia$ind.date = as.Date(vaxIndia$ind.date,"%y-%m-%d")
newCasesIndia$newCases.date = as.Date(newCasesIndia$newCases.date,"%y-%m-%d")
deathsIndia$deaths.date = as.Date(deathsIndia$deaths.date,"%y-%m-%d")

vaxIndia  = vaxIndia[vaxIndia$ind.date > as.Date(firstvaxdate) & vaxIndia$ind.date < as.Date(latestvaxdate),]
summary(vaxIndia)
newCasesIndia = newCasesIndia[newCasesIndia$newCases.date > as.Date(firstcasedate) & newCasesIndia$newCases.date < as.Date(latestcasedate),]
summary(newCasesIndia)
deathsIndia = deathsIndia[deathsIndia$deaths.date > as.Date(firstdeathdate) & deathsIndia$deaths.date < as.Date(latestdeathdate),]
summary(deathsIndia)
```

Number of deaths is now cumulative data we need to make it non cumulative and make a data frame out of all the clean lists we made

```{r}
ndeaths = diff(c(0,deathsIndia$deaths.India))
ndeaths[1]=0
dates<-seq(from=as.Date(firstcasedate),to=as.Date(firstvaxdate-1),by='day')
vaxx<-rep(c(0), as.numeric(firstvaxdate-firstcasedate))
testdf<-data.frame(ind.date=dates,ind.people_fully_vaccinated_per_hundred=vaxx)
vaxIndia<-rbind(testdf,vaxIndia)
df = data.frame(ncases = newCasesIndia$newCases.India,vax = vaxIndia$ind.people_fully_vaccinated_per_hundred,death = ndeaths)
summary(df)
```

## Correlations

```{r}
c =  cor(df)
corrplot::corrplot.mixed(c,order='AOE')
```

### Observation :

-   We can see that vaccinations have little to no effect on number of new cases
-   New cases have a very high positive correlation with deaths
-   Vaccinations have a negative correlation with death

## plots

```{r}
plot.ts(df)
```

## Regression Model

An Explanatory model by which we intend to explain what vaccines affect the most in past using past data

```{r}
mdl = lm(death~vax*ncases,data = df)
summary(mdl)
d =  predict(mdl,newdata = df)
plot(df$death,type = "l")
lines(d,col="red")
```

### Result :

Hence we can see that Vaccines don't impact the number new cases that come everyday but what they do is increase the mortality and give vaccinated people a better chance to live if they do get affected by corona

## Auto-ARIMA Model

Implementing an Auto-ARIMA model to predict nearby cases.

For this we need to convert the dataset into a timeseries data. We initialize dates as a seq by day and attach the dataframe (dfarmima).

```{r}
library(forecast)
dfarima = data.frame(ncases = newCasesIndia$newCases.India)
summary(dfarima)

set.seed(123)
inds = seq(firstcasedate,latestcasedate, by="day")
arima_ds = ts(dfarima, frequency = 365,
                 start = c(2020, as.numeric(format(inds[1],"%j"))),
                 end = c(2022, as.numeric(format(inds[821],"%j"))))
```

### Training and validation sets

```{r}
training_set = window(arima_ds, start = c(2020, 22), end = c(2022, 10))
validation_set = window(arima_ds, start = c(2022, 11), end = c(2022,111 ))

autoplot(training_set, main = 'Training set',xlab = 'Timeline',ylab = 'Number of Cases per million')
```

## Forecasting

Here we use forecast library to train the auto-ARIMA model to predict next 10 days of new cases. For validation we use the validation_set to verify the prediction.

```{r}
fit_arima<- auto.arima(training_set,seasonal = TRUE)
summary(fit_arima)
fcast<-forecast(fit_arima,h=30)
autoplot(fcast,main = 'Forecast for 10 days',xlab = 'Timeline',ylab = 'New Cases')

print(fcast)

print(validation_set[1:30])

acc_arima = accuracy(fcast,x = validation_set)
```
## Result

Here, we observe our auto-ARIMA model was able to predict the new number of cases for next couple of days.

## Facebook prophet model
```{r}
#newvac<-read_csv("vac.csv",show_col_types = FALSE)
#newcases<-read_csv("cases.csv",show_col_types = FALSE)
library("dplyr")
library("prophet")
library("ggplot2")
library("tsbox")
fb_frame = newCasesIndia
fb_frame$floor <- 0

# Facebook prophet model expects columns to be with specific names.
colnames(fb_frame) <- c("ds", "y","floor")

#fb_frame = rename(fb_frame, c(ds="newCases.date", y="newCases.India"))

# Split dataset into train and test set.
fb_train = fb_frame[1:length(fb_frame)-30,]
fb_test = fb_frame[length(fb_frame)-30:length(fb_frame),]

m <- prophet(df=fb_frame,growth = "linear",seasonality.mode = "additive", seasonality.prior.scale =10,yearly.seasonality=TRUE,changepoint.prior.scale = 0.05)
#multiplicative seems overfitting

future = make_future_dataframe(m, periods = 30)
future$floor <- 0

fb_forecast = predict(m, future)
fb_forecast1 = fb_forecast[c('ds','yhat')]

plot(m, fb_forecast1, xlab = "Timeline",ylab = "New cases per million")

# Plot forecast and test set.
ts_ggplot(Forecast=ts(fb_forecast1$yhat), Data=ts(fb_test$y))
tail(fb_forecast1)

# Plotting forecast components.
prophet_plot_components(m, fb_forecast)
#verifydf<-data.frame(fb_forecast$ds,fb_forecast$yhat,fb_frame$y[1:280])

```

## Observations

Facebook's Prophet algorithm is widely used in time series forecasting. In our scenario, we observe that the model is good in predicting the lower half of the data, but, for sudden rise in data, it is not performing as expected. This can be fixed with changing the parameter seasonality.node="multiplicative" in the model parameters. But then the model exhibits over-fitting nature. At the present we forecast number of new cases in upcoming 30 days. We observe a new wave of cases in this upcoming 30 days as displayed in the plot.


